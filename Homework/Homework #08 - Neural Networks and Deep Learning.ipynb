{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8615a3",
   "metadata": {},
   "source": [
    "### Model Structure\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5af7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26cfa66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(150, 150, 3))\n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(input)\n",
    "layer2 = MaxPooling2D(pool_size=(2, 2))(layer1)\n",
    "layer3 = Flatten()(layer2)\n",
    "layer4 = Dense(64, activation='relu')(layer3)\n",
    "output = Dense(1, activation='sigmoid')(layer4)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a238fb3",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- `binary crossentropy`\n",
    "- `focal loss`\n",
    "- `mean squared error`\n",
    "- `categorical crossentropy`\n",
    "\n",
    "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9f610",
   "metadata": {},
   "source": [
    "**A: for binary classification problems, binary crossentropy should be the best loss function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003fa8e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use the `summary` method for that. \n",
    "\n",
    "- 9215873\n",
    "- 11215873\n",
    "- 14215873\n",
    "- 19215873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff4e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bee865",
   "metadata": {},
   "source": [
    "**A: 11215873**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f46583",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/val directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and validation \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f78b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "    'archive/train',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = gen.flow_from_directory(\n",
    "    'archive/test',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "399dfa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 21s 250ms/step - loss: 0.6249 - accuracy: 0.6330 - val_loss: 0.5075 - val_accuracy: 0.7614\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 12s 149ms/step - loss: 0.4616 - accuracy: 0.7974 - val_loss: 0.4181 - val_accuracy: 0.8249\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.3890 - accuracy: 0.8356 - val_loss: 0.5077 - val_accuracy: 0.7335\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.3297 - accuracy: 0.8714 - val_loss: 0.3204 - val_accuracy: 0.8629\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 12s 156ms/step - loss: 0.2872 - accuracy: 0.8890 - val_loss: 0.3463 - val_accuracy: 0.8350\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.2673 - accuracy: 0.9040 - val_loss: 0.2943 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.2185 - accuracy: 0.9184 - val_loss: 0.2762 - val_accuracy: 0.8807\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.2110 - accuracy: 0.9197 - val_loss: 0.3285 - val_accuracy: 0.8655\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 12s 144ms/step - loss: 0.1837 - accuracy: 0.9379 - val_loss: 0.2815 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 0.1559 - accuracy: 0.9536 - val_loss: 0.2678 - val_accuracy: 0.8909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb1790",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.40\n",
    "- 0.60\n",
    "- 0.90\n",
    "- 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04266f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6249135136604309,\n",
       "  0.46162909269332886,\n",
       "  0.38897058367729187,\n",
       "  0.3297272324562073,\n",
       "  0.2872343957424164,\n",
       "  0.2672862112522125,\n",
       "  0.21846544742584229,\n",
       "  0.21099267899990082,\n",
       "  0.18368424475193024,\n",
       "  0.15593062341213226],\n",
       " 'accuracy': [0.6329987645149231,\n",
       "  0.797365128993988,\n",
       "  0.8356336355209351,\n",
       "  0.8713927268981934,\n",
       "  0.8889585733413696,\n",
       "  0.904015064239502,\n",
       "  0.9184441566467285,\n",
       "  0.9196988940238953,\n",
       "  0.9378920793533325,\n",
       "  0.9535759091377258],\n",
       " 'val_loss': [0.507524847984314,\n",
       "  0.41813090443611145,\n",
       "  0.5077062845230103,\n",
       "  0.32040873169898987,\n",
       "  0.34630948305130005,\n",
       "  0.29425951838493347,\n",
       "  0.2762324810028076,\n",
       "  0.3284505605697632,\n",
       "  0.2814604938030243,\n",
       "  0.2678177058696747],\n",
       " 'val_accuracy': [0.7614213228225708,\n",
       "  0.8248730897903442,\n",
       "  0.7335025668144226,\n",
       "  0.8629441857337952,\n",
       "  0.8350253701210022,\n",
       "  0.8857868313789368,\n",
       "  0.8807106614112854,\n",
       "  0.8654822111129761,\n",
       "  0.8680202960968018,\n",
       "  0.8908629417419434]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f726a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee587846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964868187904358"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29c139",
   "metadata": {},
   "source": [
    "\n",
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.11\n",
    "- 0.66\n",
    "- 0.99\n",
    "- 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7121c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44af366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1448835113570336"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdev(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045fa85",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=40,`\n",
    "* `width_shift_range=0.2,`\n",
    "* `height_shift_range=0.2,`\n",
    "* `shear_range=0.2,`\n",
    "* `zoom_range=0.2,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf061a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "    'archive/train',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = gen.flow_from_directory(\n",
    "    'archive/test',\n",
    "    target_size=(150, 150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3a47b",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "Make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of validation loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.15\n",
    "- 0.77\n",
    "- 0.37\n",
    "- 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dbc8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 21s 262ms/step - loss: 0.4120 - accuracy: 0.8093 - val_loss: 0.4023 - val_accuracy: 0.8147\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 0.3926 - accuracy: 0.8199 - val_loss: 0.4122 - val_accuracy: 0.8071\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 20s 250ms/step - loss: 0.3710 - accuracy: 0.8300 - val_loss: 0.3533 - val_accuracy: 0.8477\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 20s 252ms/step - loss: 0.3439 - accuracy: 0.8614 - val_loss: 0.3306 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 20s 255ms/step - loss: 0.3622 - accuracy: 0.8457 - val_loss: 0.3906 - val_accuracy: 0.8503\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 0.3586 - accuracy: 0.8425 - val_loss: 0.3751 - val_accuracy: 0.8553\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 20s 256ms/step - loss: 0.3509 - accuracy: 0.8394 - val_loss: 0.3280 - val_accuracy: 0.8629\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 20s 251ms/step - loss: 0.3434 - accuracy: 0.8488 - val_loss: 0.3279 - val_accuracy: 0.8604\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 0.3325 - accuracy: 0.8538 - val_loss: 0.3665 - val_accuracy: 0.8401\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 20s 256ms/step - loss: 0.3260 - accuracy: 0.8632 - val_loss: 0.3398 - val_accuracy: 0.8680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f4e7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3150cd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3626246780157089"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4b53e",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of validation accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "- 0.84\n",
    "- 0.54\n",
    "- 0.44\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17d188ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573604106903077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(history.history['val_accuracy'][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9b09ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "988ba623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f5be838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('./archive/test/dragon/1e07914f-530e-4087-a377-cded306c360c.jpg', target_size=(150,150))\n",
    "X = np.array(img)\n",
    "X = np.array([X])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15730c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "998eb1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.18431371,  0.12941182,  0.14509809],\n",
       "         [-0.15294117,  0.16078436,  0.17647064],\n",
       "         [-0.09803921,  0.21568632,  0.2313726 ],\n",
       "         ...,\n",
       "         [-0.09019607,  0.2313726 ,  0.26274514],\n",
       "         [-0.11372548,  0.20784318,  0.23921573],\n",
       "         [-0.11372548,  0.20784318,  0.23921573]],\n",
       "\n",
       "        [[-0.16862744,  0.14509809,  0.16078436],\n",
       "         [-0.14509803,  0.1686275 ,  0.18431377],\n",
       "         [-0.12941176,  0.18431377,  0.20000005],\n",
       "         ...,\n",
       "         [-0.11372548,  0.20784318,  0.23921573],\n",
       "         [-0.02745098,  0.2941177 ,  0.32549024],\n",
       "         [-0.12156862,  0.20000005,  0.2313726 ]],\n",
       "\n",
       "        [[-0.19215685,  0.12156868,  0.13725495],\n",
       "         [-0.10588235,  0.20784318,  0.22352946],\n",
       "         [-0.0745098 ,  0.23921573,  0.254902  ],\n",
       "         ...,\n",
       "         [-0.08235294,  0.23921573,  0.27058828],\n",
       "         [-0.09019607,  0.2313726 ,  0.26274514],\n",
       "         [-0.1607843 ,  0.16078436,  0.19215691]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.12156862,  0.22352946,  0.2313726 ],\n",
       "         [-0.08235294,  0.26274514,  0.27058828],\n",
       "         [-0.10588235,  0.23921573,  0.24705887],\n",
       "         ...,\n",
       "         [-0.09803921,  0.24705887,  0.27058828],\n",
       "         [-0.15294117,  0.19215691,  0.21568632],\n",
       "         [-0.15294117,  0.19215691,  0.21568632]],\n",
       "\n",
       "        [[-0.12941176,  0.21568632,  0.22352946],\n",
       "         [-0.17647058,  0.1686275 ,  0.17647064],\n",
       "         [-0.1372549 ,  0.20784318,  0.21568632],\n",
       "         ...,\n",
       "         [-0.09803921,  0.24705887,  0.27058828],\n",
       "         [-0.10588235,  0.23921573,  0.26274514],\n",
       "         [-0.15294117,  0.19215691,  0.21568632]],\n",
       "\n",
       "        [[-0.12156862,  0.22352946,  0.2313726 ],\n",
       "         [-0.12156862,  0.22352946,  0.2313726 ],\n",
       "         [-0.09803921,  0.24705887,  0.254902  ],\n",
       "         ...,\n",
       "         [-0.09019607,  0.254902  ,  0.27843142],\n",
       "         [-0.12156862,  0.22352946,  0.24705887],\n",
       "         [-0.12941176,  0.21568632,  0.23921573]]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e640bce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1513a243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dino': 0, 'dragon': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee067f",
   "metadata": {},
   "source": [
    "yay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
